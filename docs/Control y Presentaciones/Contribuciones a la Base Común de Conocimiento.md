<div style={{ display: 'flex' }}>
  <img src="/img/TalentLOGO.png" alt="Imagen 1" style={{ width: '50%', height: 'auto' }} />
  <img src="/img/USLOGO.png" alt="Imagen 2" style={{ width: '30%', height: '30%' }} />
</div>

## <center>Ingeniería del Software y Práctica Profesional - Universidad de Sevilla</center>

BERMEJO SORIA, CARLOS

CASAL FERRERO, RUBÉN

DOMÍNGUEZ RUIZ. ANDRÉS

DOMÍNGUEZ-ADAME RUIZ. ALBERTO

FERNÁNDEZ CASTILLO, JAVIER

GALLARDO MARTOS, DANIEL

HERRERA RAMIREZ, ISMAEL

IZQUIERDO LAVADO, MARIO

MATEOS GÓMEZ, FERNANDO JOSÉ

MERINO PALMA, ALEJANDRO JOSÉ

MONTERO MARTÍNEZ, FRANCISCO JESÚS

LÓPEZ MOYANO, ROCÍO

OTERO BARBASÁN, MANUEL

VILAPLANA DE TRÍAS, FRANCISCO DAVID

ZARZUELA REINA, CARLOS



### Entregable: S1
### Grupo 01 (Mañana) - IT Talent


# <a name="_z05qqri5g3tk"></a>Control de Versiones


|**Versión**|**Fecha**|**Autor**|**Cambios**|
| :- | :- | :- | :- |
|v1.0|18/02/24|Paco, Fernando, Ismael|Documento inicial|
|v2.0|26/02/24|Paco|Cambio en el formato y adición del contenido de la 3a semana|
|v2.1|03/03/24|Paco|Adición de contenido de la 4a semana|

## **Resumen del documento**
En este documento se especifican las contribuciones a la base de conocimientos de la asignatura disponible en [este enlace](https://bgcc.vercel.app/). También se recogen las acciones que se han tomado teniendo en cuenta el feedback proporcionado de una semana a otra.

Índice

[1. Contribuciones 4](#_3znysh7)

[Feedback del grupo 1 4](#_2et92p0)

[Feedback general 7](#_tyjcwt)

[2. Acciones de consolidación 12](#_hdsb3nxfaesu)

[Semana 1 12](#_p67pcua0m0xx)

[Semana 2 12](#_ku3gg0ccc2wk)

[Semana 3 14](#_nr1e6pggn0b5)

[Semana 4 15](#_89jjyhvougww)

# 1. Contribuciones
Para las contribuciones se llega a un acuerdo de que cada semana será un grupo el encargado de recoger todo el feedback general de esa sesión y desplegarlo en la página <https://bgcc.vercel.app/>. Pero cada grupo tendrá como encargo semanalmente subir el feedback de su propio grupo, además de revisar el general en busca de posibles carencias en este.

## Feedback del grupo 1

- **Semana 1**

1. Las diferencias con el resto de competidores deben quedar suficientemente claras. Distinguir la “puesta en marcha” del resto de costes, ¿Cuál es el TCO?.
1. Tener en cuenta los costes de la plataforma (p.e: operaciones), añadir planes sobre qué hacer en caso del aumento o disminución de usuarios.
1. Se deben identificar las responsabilidades (están bien hechos los grupos) para cada grupo.
1. Explicar cuál ha sido el proceso y criterio de búsqueda con los competidores.
1. Evitar que sobre demasiado tiempo sobre todo si se puede profundizar en otros temas como la búsqueda de competidores.
1. Evitar permanecer demasiado tiempo en una diapositiva o dejar explicación sin soporte visual, hace complicado seguir la presentación.
1. Relacionar entre sí las matrices DAFO p.e: Amenazas vs Fortalezas… concretamente: 1ºA, 2ºF, 3º D, 4º O
1. No son preferibles las estructuras jerárquicas con jefes y planificaciones. Son preferibles roles claros.
1. Hay que hablar la base de conocimientos común.
1. Tratar de homogeneizar las fotos de los participantes, que no tengan fondos muy diferentes.
1. En los costes no poner los céntimos en la presentación, no es necesario ese nivel de detalle, en vez de 61.120,60€ poner 60k.
1. Tratar de mantener un volumen de voz alto.
1. No hacer preguntas al público.

- **Semana 2**

1. Hay que comenzar las presentaciones de manera clara con un “Impacto” inicial. Importancia de los “Killer openers”. (Hay una píldora que lo trata)
1. Dar gran protagonismo a los casos de uso core, la idea de negocio y los mockups.
1. Si se comparan competidores o herramientas similares se debe hacer hincapié en el elemento diferenciador.
1. Si existen alternativas gratuitas al comparar competidores se debe justificar qué provocaría el cambio/paso a nuestra herramienta.
1. Si es un elemento el que nos diferencia de la competencia, el pricing debería ir enfocado a este.
1. Las promesas no deben ir al final, si no al inicio para usarlas como enganche para el público. Los mockups al final
1. Cuando se dicen riesgos debe estar claramente identificado de qué manera podría pasar y cómo se solucionaría con detalle. (Por ejemplo, si uno es falta de conocimiento y se propone una formación, especificar la duración de la misma).
1. Al comentar el commitment agreement, se deben exponer posibles problemas de equipo que ejemplifiquen. (Por ejemplo, si alguién no tiene una tarea tiempo, ¿Qué va a pasar?)
1. Promover y mostrar la evolución del commitment agreement además de medir cómo se cumple.
1. El TCO debe estar expresado de manera mensual no anual.
1. Al exponer un riesgo es importante describirlo como un evento que puede ocurrir y describir los daños o pérdidas que causaría.
1. Si se expone un riesgo, se presenta la solución por delante.
1. Los análisis de costes son más inteligibles en forma de tabla.
1. Los costes de herramientas y/o licencias de pago (por ejemplo github) deben ser tenidos en cuenta. Si es un servicio gratuito se debe exponer la existencia de un plan si este deja de serlo.
1. Dejar claro que TODOS los integrantes han firmado el commitment agreement.
1. No sentarse en la mesa para exponer.
1. Un fondo negro dificulta la lectura.
1. Uso de fuentes anchas y grandes.
1. Al proponer precios debe quedar claro los beneficios que se están sacando (TCO).
1. Siempre tener en cuenta el feedback de semanas anteriores al exponer. Marcar con una “F” las diapositivas que hacen referencia a este feedback.
1. Evitar el uso de iconografías sin descripción en la comparación con otras empresas.
1. Dejar claro que el uso de RRSS para el registro es opcional, nunca se pretende ser intrusivo en la vida personal del candidato, lo último que buscamos es perturbarlo con estos análisis.
1. Dar mayor protagonismo a los mockups, casos de uso core y la idea de negocio.
1. Hay que asumir los costes de github y tenerlos en cuenta. Si asumimos que es gratuita la licencia, ¿Qué pasaría si no? ¿Cuántas github action usaremos al mes?
1. Se debe dejar claro de dónde sale el cálculo de precios y cuál es el beneficio que se saca de estos.

- **Semana 3**

1. Si se realiza un Killer Opener, este debe ser corto. Si se demora demasiado deja de ser efectivo.
1. Situar la marca de feedback en la parte superior de la presentación.
1. Al presentar los mockups realizar zoom cuando se haga referencia a partes concretas que no sean legibles al fondo de la clase.
1. Es importante “afilar” los argumentos, sintetizar de manera que quede solo lo esencial.
1. Al comparar con los competidores hacer énfasis en los puntos que mejora nuestra aplicación.
1. Dejar claro el estado de la comunicación con los usuarios pilotos.
1. Dejar claro el versionado que se usará en la gestión del código.
1. Tener una gestión de la documentación similar a la del código con github. Por ejemplo, la presentación debería subirse como una pull request con todo el grupo como revisor.
1. Se debe dejar claro que la presentación ha sido revisada y escuchada por todos los miembros del equipo y que estos han aportado su feedback.
1. Si se han aplicado medidas para solucionar un problema hay que plasmar, evaluar y medir cómo de buenas han sido estas.
1. Tener claros y plasmar las metas y objetivos de cada sprint.
1. No quejarse NUNCA en medio de la presentación.

- **Semana 4**

1. No suspirar a lo largo de la presentación, da sensación de agotamiento de lo que se está contando. Aclarar y enlazar el Killer Opener con el inicio y el resto de la presentación.
1. Falta claridad en el TCO. Se necesita definir un marco de tiempo (time frame) y una capacidad de demanda nominal para comprender mejor cómo se comportará el sistema en diferentes condiciones de uso, en resumen, cómo escalará. No solo se trata de cuántos usuarios pueden usarlo al mismo tiempo, sino también de cuándo y con qué nivel de demanda.
1. Hablar en profundidad de nuestra gestión de la documentación, mostrar el versionado de documentos que se lleva internamente.
1. En la presentación deben quedar claros los análisis del rendimiento y los límites operativos de github (github actions) para justificar el plan que necesitamos. Por ejemplo, cuánto tarda en evaluar a X usuarios para formar un grupo.
1. La tabla de TEAM PERFORMANCE está bien, no cambiarla demasiado, pero le ha faltado la performance individual.
1. Faltan gráficas y métricas del rendimiento por cada integrante del equipo (anónimo).
1. Las métricas del rendimiento debe ser capaz de comparar cada miembro del equipo y los datos obtenidos deben ser cotejados para evaluar al final de cada sprint. Para los que programan es sencillo; nº de commits… Pero ¿Cómo se está midiendo el rendimiento de la persona que coordina?
1. El DAFO ya no merece la pena incluirlo en la presentación.
1. Diferencias entre gitflow y goldenflow y decir cual nos merece la pena usar.
1. El número de usuarios que necesitamos para mantener la aplicación debe tener porcentajes con respecto al número de personas en el sector en Sevilla por ejemplo.
1. Pensar en si es mejor una DEMO grabada o en directo.
1. Marcar más el reconocimiento que se dice que se tiene sobre el CA. Poner un pódium con los nombres.

- **Semana 5**

1. Eliminar la captura del formulario, no es legible.
1. Falta un Elevator pitch claro.
1. Cambiar MPV por MVP.
1. Tener una demo grabada.
1. Para en la demo empezar por lo más importante, no el login.
1. Demasiados datos en el TCO, hacen complejo entender y seguir la presentación.
1. Las estimaciones a futuro (BUDGET) NO pueden ser lineales, datos como el número de usuarios deben hacer fluctuar los datos.
1. Evitar colores claros sobre blanco en los gráficos y poner etiquetas en cada eje.
1. Hacer poner la clave de github (API) al cliente es arriesgado si la empresa es la que tiene que hacer los análisis. Sobre todo si el cliente ya usa su api para otras cosas, el requisito de uso es demasiado alto, no es profesional.
1. Estimar el número de peticiones que se deberían hacer en total y decir cuánto nos costaría con la responsabilidad de usar la API nosotros.
1. Deberíamos haber hecho el análisis de la capacidad de peticiones, para estimar el nº de peticiones óptimo para los clientes en los diferentes planes de subscripción.
1. Tendríamos que hacer el análisis económico de las peticiones que harán los clientes.
1. Estimaciones de usuarios (optimistas, pesimistas, realistas) más simple, realizar análisis PERT.
1. Realizar un pseudo gantt en la retrospectiva del sprint con las tareas que se han realizado en este.
1. Incluir documentación en el repositorio o en un docusaurus.



<a name="_tyjcwt"></a>**Feedback general**

------------------------------------------
**Presentadores**

“Segmentar las ideas” de tal manera que queden claros los mensajes clave.

Evitar permanecer demasiado tiempo en una diapositiva o dejar explicación sin soporte visual.

Dar énfasis a ciertos puntos críticos de la presentación para mantener la atención del público, cambiando la entonación para que no sea demasiado monótona.

Aunque se realice un Killer Opener, los presentadores deben recordar decir sus nombres.

Recordar que como presentador no recae en uno las responsabilidades del grupo al completo, disfrutar de la presentación.

Aclarar y enlazar el Killer Opener con el inicio y el resto de la presentación.

No olvidar que es el moderador (no nuestro grupo) quien lleva el conteo del tiempo (fuera de evaluación) de las presentaciones.

Cuidar y evitar las muletillas.

No suspirar a lo largo de la presentación, da sensación de agotamiento de lo que se está contando.

Siempre cuidar y tener claro el hilo de la presentación. Debe de haber coherencia entre los puntos y no dejar conceptos sueltos.




`	`**Presentación**

Tratar de homogeneizar las fotos de los participantes, que no tengan fondos muy diferentes.

Las demos de los prototipos se deben ver bien, hacer zoom si es necesario.

Evitar letras blancas sobre colores claros.

Si hay datos en el tiempo (días) poner como apoyo visual un calendario.

Se debe ser coherente lo que se refleja en la diapositiva con lo que pone en el título.

Evitar sobrecarga en las presentaciones, buscar la simplicidad y la correlación entre diapositivas.

Marcar más el reconocimiento que se dice que se tiene sobre el Commitment Agreement. Poner un pódium con los nombres.

Usar recursos en la presentación como líneas o subrayados para corresponder con lo que se dice.

El DAFO ya no merece la pena incluirlo en la presentación.

Pensar en si es mejor una DEMO grabada o en directo.

Indicar con triángulos hacia arriba o abajo cuando haya habido rendimiento positivo o negativo en la retrospectiva.

Siempre debe haber una transparencia con la productividad por miembro del equipo (horas).

Si se dicen las tareas que ha hecho cada subgrupo deben ir acompañadas de un diagrama de gantt simplificado o similar en el que se vean para cuando estaba planificada cada una.

No meter una imagen de un QR si no es funcional o al menos aclarar que no lo es.

No basta con mostrar los problemas que ha habido durante la semana de trabajo, se debe mostrar siempre el análisis de riesgos inicial.

No mezclar la retrospectiva con la autoevaluación.

Debe quedar reflejado en la presentación que cuando no se llega el trabajo planificado se ha incumplido alguna cláusula del Commitment Agreement.

Deben quedar claro los responsables de una tarea.

En la presentación deben quedar claros los análisis del rendimiento y los límites operativos de github (github actions) para justificar el plan que necesitamos. Por ejemplo, cuánto tarda en evaluar a X usuarios para formar un grupo.

En la autoevaluación debe haber un análisis con métricas y números claros.

Siempre que se muestren problemas en el trabajo en equipo en la presentación, se mostrarán las medidas que se tomarán para solventarlos con las métricas con las que se medirá la eficacia de las respuestas.

A cada sprint siempre se debe mostrar la planificación o re-planificación de los próximos sprints.

Se busca una mejora de la síntesis cada semana, no se deben eliminar conceptos de una a otra.

Mantener siempre una diapositiva con la Landing Page con QR aunque sea en la última diapositiva.

Siempre incluir los estados de la comunicación en la gestión de usuarios pilotos.

**Análisis de competidores**

En vez de situar competidores o elementos en lista (de ventajas y desventajas), realizar un mapa y agruparlos por similaridad para evaluarlos de esta manera.

Pese a estar en la fase de desarrollo el análisis de competidores siempre debe estar presente en las presentaciones.

Para un análisis de competidores más sintetizado es suficiente con pararse en los tres más similares a nuestra plataforma focalizando en la característica más “killer”.

**Análisis de costes**

Cuanto mayores son los números en cuanto a ROI mayor debe ser el Elevator Pitch, orientado a estos números. Si son poco realistas deben ser repensados.

No confundir coste de mantenimiento con coste de operación, el mantenimiento puede ser por ejemplo el correctivo (para posibles fallos) o aumentativo (hay suficiente dinero como para hacer añadidos).

Para el TCO es pertinente definir un marco de tiempo (time frame) y una capacidad de demanda nominal para comprender mejor cómo se comportará el sistema en diferentes condiciones de uso, en resumen, cómo escalará. No solo se trata de cuántos usuarios pueden usarlo al mismo tiempo, sino también de cuándo y con qué nivel de demanda.

Hablar de porcentajes del número de usuarios que tienen que usar nuestra aplicación (TCO) con respecto al número de usuarios potenciales.

El número de usuarios que necesitamos para mantener la aplicación debe tener porcentajes con respecto al número de personas en el sector en Sevilla por ejemplo.

**Documentación**

Reflejar en el Commitment Agreement cuando personas tiene penalizaciones o “ya no van a por el 10”.

**Proyecto en general**

Se debe dejar claro la planificación de cada sprint, sobre todo si ha habido problemas de rendimiento en una semana, ¿Cómo afectan las carencias en este sprint a los próximos sprints?

Si no se llega al 100% del trabajo que se pedía, se debe justificar con un motivo de peso o penalizaciones sobre el Commitment Agreement o la evaluación grupal de la persona implicada.

El rendimiento no es la inversión del tiempo si no el uso efectivo del mismo.

El rendimiento se debe medir individualmente y no en grupo.

Si hay una propuesta de mejora se debe decir cómo se va a medir de antemano, antes de tomar la medida.

Las métricas del rendimiento debe ser capaz de comparar cada miembro del equipo y los datos obtenidos deben ser cotejados para evaluar al final de cada sprint. Para los que programan es sencillo; nº de commits… Pero ¿Cómo se está midiendo el rendimiento de la persona que coordina?

Durante el desarrollo dar preferencia a las funcionalidades core o del MVP, por ejemplo, si el login es secundario no debería estar siendo desarrollado en el primer sprint cuando el objetivo es acabar el MVP.

El testing no puede estar presente solamente en el sprint 3, deben ser FAST, se deben hacer a lo largo de todos los sprints.

En caso de tener problemas en el desarrollo, siempre valorar la posibilidad de mover tareas de un sprint a otro.


**



# 2. <a name="_hdsb3nxfaesu"></a>Acciones de consolidación
Tras recoger el feedback semanal han de ser evaluados y realizar los cambios pertinentes sobre el proyecto, aquí se recogen estos cambios.
## <a name="_p67pcua0m0xx"></a>**Semana 1**

**Costes**

Se realizó el análisis de costes orientado a distinguir los costes de puesta en marcha, costes  de desarrollo,  costes de mantenimiento y coste total de propiedad. Además, se han añadido planes de acción en cuanto a la variación del volumen de usuarios. Se ha explicado el proceso que se ha seguido(teniendo en cuenta las píldoras teóricas) para identificar a los competidores.

**Commitment Agreement**

Se deja claro en el commitment agreement en quién recae la responsabilidad de una tarea en el grupo. Es el coordinador el que la piensa y asigna, pero la responsabilidad de la no realización de la misma recae sobre el asignado, a no ser que se avisara con tiempo suficiente como para poder encargársela a otro en día laboral.

**Presentación**

Se redujo la carga de las diapositivas, aumentando su cantidad y usando un mayor número de referencias simbólicas. Se tuvo en cuenta y se explica ahora la matriz DAFO empezando por Debilidades y Fortalezas, y luego Amenazas y Oportunidades. Nos hicimos fotos con el mismo fondo y pose. Pusimos los costos con un número sin decimales. Se dejó de lanzar preguntas al público sin que estuviera acordado entre ellos.


<a name="_ku3gg0ccc2wk"></a>**Semana 2**

----------------------------------------
**Presentador**

Se ha preparado un Killer opener más impactante unido a un Elevator Pitch, además de evitar sentarse durante la exposición.

**Presentación**

Se le dedica más tiempo en la exposición a desarrollar la idea de negocio y el core. No se usaba fondo negro, pero se aumenta el tamaño de la letra y fuente.

Se ha incluido promesas en la parte de la idea de negocio, y de definición del producto. Los mockups se han movido al final. Se ha cambiado la expresión del TCO a meses, y se expresa con más detalles los gastos y costes. Se indica con una “F” las partes donde se ha tenido en cuenta el feedback. Se ha aclarado que el uso de RRSS es opcional y siempre por parte del candidato. Se usan iconos con breve descripción, no sólo símbolos sueltos.

**Comparaciones**

Hemos analizado y remarcado cuales son nuestras diferencias más importantes del resto de competidores. No existen competidores que ofrezcan el servicio de forma gratuita. Además, el pricing ha sido actualizado para orientarlo a nuestro producto y hacerlo más llamativo(palabras claves y letras más grandes).

**Commitment agreement**

Se han realizado cambios en el commitment agreement sobre en quién recae la responsabilidad de una tarea y las recompensas del trabajo semanal individual, dando a un total de 15 cláusulas que volvieron a firmar los integrantes del equipo.

**Riesgos**

Se indica de manera explícita como solventar los riesgos y se ha aumentado el número de estos. Se describe el riesgo como evento, no como “problema”.

**Costes**

Se han añadido las licencias necesarias(Github) al análisis de costes. Además se ha calculado cuáles serán las ganancias.



## <a name="_nr1e6pggn0b5"></a>**Semana 3**

**Presentador**

Se trabaja sobre el Killer Opener y se elabora una historia como introducción más corta y directa. Para lidiar con problemas durante la exposición el presentador del grupo se ha grabado realizándola y la ha mandado a todo el grupo dándole este último apuntes y consejos sobre que puede ser obviado o qué no puede faltar, de esta manera es capaz de practicar la presentación y además afilar más los argumentos quitando lo innecesario.


**Presentación**

Para la presentación se toman en cuenta los comentarios que realizó el público y; se cambia la posición de la marca del feedback a la parte superior de las transparencias y se procura que en todo momento las letras estén lo suficientemente grandes o destacadas.

También se remarcan aún más nuestras diferencias con los competidores en la transparencia correspondiente.

**Comunicación**

Se mantiene el contacto con nuestros usuarios pilotos y dejamos claro que iremos avisando de cuando tengamos demos que puedan testear. Por su parte nos dan ya una fecha, el 28 de febrero, en la que tendríamos su demo.

Con respecto a las empresas contactadas, el estado de comunicación con estos es el mismo, una ha confirmado y el resto pendientes de respuesta.

**Retrospectiva**

Se han tomado medidas para nuestro uso del tiempo y las respuestas a estas han sido notables esta semana, por ello de momento las metas para el resto del proyecto se mantienen iguales.

**Documentación**

Tener una gestión de la documentación similar a la del código con github. Por ejemplo, la presentación debería subirse como una pull request con todo el grupo como revisor.

Seguimos con la misma metodología de gestión que habíamos tomado desde el inicio, con Drive, pero con tableros de github para controlarlos como un repositorio en el que un responsable se encarga de revisar cada documento y cada encargado de realizarlo es notificado mediante issues y si hubiera algún problema es notificado mediante comentarios en estos.

## <a name="_89jjyhvougww"></a>**Semana 4**

**Costes**

Para el TCO se nos pedía y hemos realizado nuevos análisis en lo referente al número de usuarios que podría llegar a almacenar nuestra aplicación, si éste subiera aumentaría el coste de operación ya que sería necesario ampliar servicios de github, servidores…

También volvemos a calcular los usuarios por rol estimados para que la aplicación sea rentable en tres tipos: optimista, realista y pesimista.

Por último se cambia la manera de desplegar el TCO en capex y opex.

**Consideraciones de la aplicación**

Para solucionar la velocidad de chequeos el cliente el que tiene que añadir un token a a la aplicación y realizar las llamadas a la API, recae en este el riesgo y por tanto si un cliente tiene un token inválido o a excedido el límite de llamadas a la api tendrá que crearse uno nuevo o esperarse. Aún así es complicado que se llegue a dar este límite.

Para el análisis del rendimiento, el análisis de un usuarios tarda como mucho 5 segundos, dependiendo de la cantidad de datos del usuario, pero por ejemplo, para saber cuánto tarda en evaluar a X usuarios para formar un grupo lo sabremos la semana que viene cuando esto sea implementado.

Hemos realizado un exhaustivo análisis sobre gitflow y goldenflow y nos hemos decantado por una versión de gitflow que se adecúa a nuestras necesidades.

**Rendimiento de equipo**

Hemos dado una vuelta a la manera de evaluar al equipo en cuanto a rendimiento, se mantienen las tablas que teníamos por subgrupo (debido al feedback positivo del mismo) y añadimos también el análisis individual de cada miembro (anónimo). Para realizar este análisis hemos elaborado unas fórmulas en una tabla de excel que unifican la evaluación del grupo completo, cambiando según el rol.

De momento ningún miembro no ha dejado de optar al 10.

**Riesgos**

Hemos encontrado nuevos problemas que no suponían riesgos; con los usuarios pilotos del  equipo 7 para el que estableceremos un calendario bidireccional y un problema de gestión de equipos que ha sido dividida en backend y frontend como principal subdivisión pese a seguir habiendo roles del apartado. Las medidas tomadas serán evaluadas para el próximo sprint viendo cuál ha sido el rendimiento.

**Presentación**

Dejamos reflejado a los responsables de distintas tareas de nuestro proyecto para ejemplificar la metodología de encargo de tareas del equipo.

